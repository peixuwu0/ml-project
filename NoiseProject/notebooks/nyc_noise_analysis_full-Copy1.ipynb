{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da39ca7-4282-4675-b3a0-cb2d28990e22",
   "metadata": {},
   "source": [
    "# Block 0 – Data Loading & Preprocessing\n",
    "This section loads the raw NYC 311 data, filters noise-related complaints from the last 12 months, \n",
    "and extracts essential temporal and categorical features needed for analysis and modeling.\n",
    "\n",
    "Steps:\n",
    "1. Load raw CSV  \n",
    "2. Convert datetime fields  \n",
    "3. Filter last 12 months  \n",
    "4. Keep only noise-related complaints  \n",
    "5. Create time features (month, hour, dayofweek, weekend)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4beacede-f112-46e1-82f9-4d05ff2c704f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.8 MiB for an array with shape (3513950,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/311_Service_Requests_from_2024_to_Present_20251123.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nyc311\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nyc311\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nyc311\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nyc311\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mpandas/_libs/parsers.pyx:820\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/parsers.pyx:921\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/parsers.pyx:1066\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/parsers.pyx:1120\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/parsers.pyx:1222\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/parsers.pyx:1833\u001b[0m, in \u001b[0;36mpandas._libs.parsers._try_int64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 26.8 MiB for an array with shape (3513950,) and data type int64"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Block 0 — Data Loading & Preprocessing\n",
    "# ============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_path = \"../data/311_Service_Requests_from_2024_to_Present_20251123.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d4e07d-510c-49b9-8a11-814949b191c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Created Date\"] = pd.to_datetime(df[\"Created Date\"], errors=\"coerce\")\n",
    "df[\"Closed Date\"] = pd.to_datetime(df[\"Closed Date\"], errors=\"coerce\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b72ad3-d094-461d-bac6-f9a6394415b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the start date of the most recent year\n",
    "end_date = df[\"Created Date\"].max()\n",
    "start_date = end_date - pd.DateOffset(years=1)\n",
    "\n",
    "# 3. Filter recent year\n",
    "mask_recent = (df[\"Created Date\"] >= start_date)\n",
    "\n",
    "# 4. 过滤噪音投诉\n",
    "mask_noise = df[\"Complaint Type\"].str.contains(\"Noise\", case=False, na=False)\n",
    "\n",
    "# 5. Generate final noise_df\n",
    "noise_df = df[mask_recent & mask_noise].copy()\n",
    "\n",
    "len(noise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db4664-9dc2-4545-a933-44c2f37a0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure Created Date is datetime (you've done this before, but it doesn't hurt to write it again here).\n",
    "#noise_df[\"Created Date\"] = pd.to_datetime(noise_df[\"Created Date\"], errors=\"coerce\")\n",
    "\n",
    "# Temporal features\n",
    "noise_df[\"year\"] = noise_df[\"Created Date\"].dt.year\n",
    "noise_df[\"month\"] = noise_df[\"Created Date\"].dt.month\n",
    "noise_df[\"dayofweek\"] = noise_df[\"Created Date\"].dt.dayofweek  # Monday=0\n",
    "noise_df[\"hour\"] = noise_df[\"Created Date\"].dt.hour\n",
    "\n",
    "# Is it the weekend?\n",
    "noise_df[\"is_weekend\"] = noise_df[\"dayofweek\"].isin([5, 6])\n",
    "\n",
    "noise_df[[\"Created Date\", \"Complaint Type\", \"Borough\", \"year\", \"month\", \"dayofweek\", \"hour\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbfd0a-4942-4762-96b6-d32b25e4fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df.shape, noise_df[[\"Created Date\", \"Complaint Type\", \"Descriptor\", \"Borough\", \"Agency\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1ed62-b747-4a87-bef6-00c16e775301",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df[[\"dayofweek\", \"hour\", \"is_weekend\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ccda5-cce5-45d1-8c07-105c6d7d5cd9",
   "metadata": {},
   "source": [
    "# **Block 1 — Urban Noise Patterns**\n",
    "This section provides city-level descriptive analytics, examining:\n",
    "- Monthly noise complaint trends  \n",
    "- Borough-level distribution  \n",
    "- Temporal patterns (hour × weekday heatmap)  \n",
    "- Complaint Type and Descriptor distributions  \n",
    "- Noise Type × Time structure (hour, weekday, top complaint types)\n",
    "\n",
    "These analyses answer *RQ1: What spatial and temporal patterns characterize NYC noise complaints?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685520b0-ada7-492f-b16f-5636a96dbc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly quantity trend (resampled monthly)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of noises on a monthly basis\n",
    "monthly_counts = (\n",
    "    noise_df\n",
    "    .set_index(\"Created Date\")\n",
    "    .resample(\"M\")\n",
    "    .size()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_counts.plot(marker='o')\n",
    "plt.title(\"Monthly Noise Complaints (Last 12 Months)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Complaints\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d673ba-de9e-4dd9-9033-47594d3a7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borough Noise Complaint Counts Bar Chart\n",
    "borough_counts = noise_df[\"Borough\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "borough_counts.plot(kind=\"bar\", color='skyblue')\n",
    "plt.title(\"Noise Complaints by Borough (Last 12 Months)\")\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13ed5e-ed2c-40c9-afb7-45b985141bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dayofweek × hour Heatmap\n",
    "import numpy as np\n",
    "\n",
    "pivot = noise_df.pivot_table(\n",
    "    index=\"dayofweek\",\n",
    "    columns=\"hour\",\n",
    "    values=\"Complaint Type\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.imshow(pivot, aspect=\"auto\", cmap=\"viridis\", origin=\"lower\")\n",
    "plt.title(\"Noise Complaints by Weekday and Hour (Last 12 Months)\")\n",
    "plt.colorbar(label=\"Complaint Count\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Day of Week (0 = Monday)\")\n",
    "plt.xticks(range(0, 24))\n",
    "plt.yticks(range(0, 7))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e4ef3-2052-4ced-8e2b-210bcee679d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Overall distribution of Complaint Type (Top 10)\n",
    "\n",
    "top_n = 10\n",
    "\n",
    "complaint_counts = noise_df[\"Complaint Type\"].value_counts().head(top_n)\n",
    "complaint_counts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "complaint_counts.plot(kind=\"bar\")\n",
    "plt.title(f\"Top {top_n} Noise Complaint Types (Last 12 Months)\")\n",
    "plt.xlabel(\"Complaint Type\")\n",
    "plt.ylabel(\"Number of Complaints\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec4faa-4cc6-401d-8c8a-ff9299a6ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share of each Complaint Type among all noise complaints (Top 10)\n",
    "\n",
    "complaint_share = (complaint_counts / len(noise_df)).round(4) * 100\n",
    "complaint_share = complaint_share.to_frame(name=\"percentage\")\n",
    "complaint_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b956b5-818a-414d-ba6d-53d3e5e0b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Descriptor distribution (Top 15)\n",
    "\n",
    "top_k = 15\n",
    "\n",
    "descriptor_counts = noise_df[\"Descriptor\"].value_counts().head(top_k)\n",
    "descriptor_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd6ef4-d687-41a3-b64a-dfd833ec309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "descriptor_counts.plot(kind=\"bar\")\n",
    "plt.title(f\"Top {top_k} Noise Descriptors (Last 12 Months)\")\n",
    "plt.xlabel(\"Descriptor\")\n",
    "plt.ylabel(\"Number of Complaints\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f7f4b-ac0b-44c6-84b5-2f30958a1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Borough × Complaint Type (Top 5 Types)\n",
    "\n",
    "\n",
    "top_types = noise_df[\"Complaint Type\"].value_counts().head(5).index\n",
    "\n",
    "\n",
    "subset = noise_df[noise_df[\"Complaint Type\"].isin(top_types)].copy()\n",
    "\n",
    "\n",
    "borough_type_ct = pd.crosstab(subset[\"Borough\"], subset[\"Complaint Type\"])\n",
    "\n",
    "borough_type_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86e3d5-9ed7-4f7c-b4aa-4f4ff7883e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "borough_type_ct.plot(kind=\"bar\", stacked=True)\n",
    "plt.title(\"Borough × Complaint Type (Top 5 Types)\")\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.ylabel(\"Number of Complaints\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Complaint Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27407523-b2d0-49ab-bfff-3dc7f1a6f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Type × Time Structure\n",
    "\n",
    "# Get Top 5 complaint types\n",
    "top_types = noise_df[\"Complaint Type\"].value_counts().head(5).index\n",
    "top_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fafb3-816d-4bb4-bc27-04f4db14c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only top types\n",
    "subset = noise_df[noise_df[\"Complaint Type\"].isin(top_types)].copy()\n",
    "\n",
    "# Build pivot table\n",
    "pivot_hour_type = subset.pivot_table(\n",
    "    index=\"Complaint Type\",\n",
    "    columns=\"hour\",\n",
    "    values=\"Created Date\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "pivot_hour_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bd1d1-61ac-4aa3-82a5-25b4210f68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.imshow(pivot_hour_type, aspect='auto', cmap='viridis')\n",
    "plt.title(\"Heatmap: Complaint Type × Hour (Top 5 Types)\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Complaint Type\")\n",
    "plt.colorbar(label=\"Number of Complaints\")\n",
    "plt.xticks(range(24))\n",
    "plt.yticks(range(len(top_types)), top_types)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305f11e-30fd-4be3-b713-b9d7058a6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dayofweek × Complaint Type \n",
    "pivot_dow_type = subset.pivot_table(\n",
    "    index=\"Complaint Type\",\n",
    "    columns=\"dayofweek\",\n",
    "    values=\"Created Date\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "pivot_dow_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3b07c-1576-4b7d-9ba6-4dbee02f42d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.imshow(pivot_dow_type, aspect='auto', cmap='viridis')\n",
    "plt.title(\"Heatmap: Complaint Type × Day of Week (Top 5 Types)\")\n",
    "plt.xlabel(\"Day of Week (0=Mon)\")\n",
    "plt.ylabel(\"Complaint Type\")\n",
    "plt.colorbar(label=\"Number of Complaints\")\n",
    "plt.xticks(range(7))\n",
    "plt.yticks(range(len(top_types)), top_types)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8d941-d93a-419e-9507-095502f46f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate response_hours + filter reasonable response times + define closed_24h\n",
    "import numpy as np\n",
    "\n",
    "#Calculate response time (hours)\n",
    "noise_df[\"response_hours\"] = (\n",
    "    noise_df[\"Closed Date\"] - noise_df[\"Created Date\"]\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# 2. Only keep records with a Closed Date and a reasonable response time.\n",
    "# Remove records without a close date, negative values, and extremely unreasonable values (over 7 days).\n",
    "mask_valid = (\n",
    "    noise_df[\"response_hours\"].notna()\n",
    "    & (noise_df[\"response_hours\"] >= 0)\n",
    "    & (noise_df[\"response_hours\"] <= 24 * 7)\n",
    ")\n",
    "\n",
    "model_df = noise_df[mask_valid].copy()\n",
    "\n",
    "# 3.Define label: Closed within 24 hours?\n",
    "model_df[\"closed_24h\"] = (model_df[\"response_hours\"] <= 24).astype(int)\n",
    "\n",
    "model_df[[\"response_hours\", \"closed_24h\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e70c2-4f51-49d7-8679-1e0d1450a69d",
   "metadata": {},
   "source": [
    "# **Block 2 — Response Efficiency & Institutional Patterns**\n",
    "This section evaluates how quickly different agencies respond to noise complaints.  \n",
    "We analyze:\n",
    "- Response time (in hours)\n",
    "- 24-hour closure indicator\n",
    "- Agency-level efficiency\n",
    "- Temporal efficiency (hour-of-day, day-of-week)\n",
    "- Agency × Hour interaction\n",
    "- Complaint Type differences\n",
    "- Missingness patterns\n",
    "\n",
    "These analyses support *RQ2: What factors influence whether a complaint is closed within 24 hours?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816f572-abf6-4f65-8bb7-ec67a34ef49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Agency-level response efficiency\n",
    "\n",
    "agency_stats = (\n",
    "    model_df\n",
    "    .groupby(\"Agency\")\n",
    "    .agg(\n",
    "        n_cases=(\"closed_24h\", \"size\"),\n",
    "        closed_24h_rate=(\"closed_24h\", \"mean\"),\n",
    "        median_response_hours=(\"response_hours\", \"median\"),\n",
    "        mean_response_hours=(\"response_hours\", \"mean\"),\n",
    "    )\n",
    "    .sort_values(\"closed_24h_rate\", ascending=False)\n",
    ")\n",
    "\n",
    "agency_stats.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4d1ce-8d40-44a3-896a-be7036f0bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "agency_stats[\"closed_24h_rate\"].sort_values().plot(kind=\"barh\", color=\"steelblue\")\n",
    "plt.title(\"24h Closure Rate by Agency\")\n",
    "plt.xlabel(\"Proportion closed within 24h\")\n",
    "plt.ylabel(\"Agency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295e65e-8900-4e56-a558-f5e2f62a6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = (\n",
    "    model_df\n",
    "    .groupby(\"hour\")[\"closed_24h\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "hourly.plot(marker='o')\n",
    "plt.title(\"24h Closure Rate by Hour of Day\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Proportion Closed Within 24h\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b202a36-445b-4bc8-a46f-03cc41b12e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dow = (\n",
    "    model_df\n",
    "    .groupby(\"dayofweek\")[\"closed_24h\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "dow.plot(marker='o')\n",
    "plt.title(\"24h Closure Rate by Day of Week (0 = Mon)\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Proportion Closed Within 24h\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d5c13-8e65-441a-b739-ea042f4349b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_hour = (\n",
    "    model_df\n",
    "    .groupby([\"Agency\", \"hour\"])[\"closed_24h\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for agency in agency_hour[\"Agency\"].unique():\n",
    "    subset = agency_hour[agency_hour[\"Agency\"] == agency]\n",
    "    plt.plot(subset[\"hour\"], subset[\"closed_24h\"], marker='o', label=agency)\n",
    "\n",
    "plt.title(\"24h Closure Rate by Hour × Agency\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Proportion Closed Within 24h\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b46565-0eed-4aca-a259-27c99cfe4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ct = noise_df[\"Complaint Type\"].value_counts().head(10).index\n",
    "\n",
    "type_stats = (\n",
    "    model_df[model_df[\"Complaint Type\"].isin(top_ct)]\n",
    "    .groupby(\"Complaint Type\")[\"closed_24h\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "type_stats.plot(kind=\"barh\")\n",
    "plt.title(\"24h Closure Rate by Complaint Type (Top 10)\")\n",
    "plt.xlabel(\"Proportion Closed Within 24h\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d241bff-c449-4f4e-b4d2-dfa69946396f",
   "metadata": {},
   "source": [
    "# **Block 3 — Predictive Modeling & Model Interpretation**\n",
    "This section builds machine learning models to predict whether a noise complaint will be closed within 24 hours.  \n",
    "Models include:\n",
    "- Logistic Regression (baseline)\n",
    "- Random Forest (primary model)\n",
    "\n",
    "We compare performance using:\n",
    "- ROC-AUC  \n",
    "- PR-AUC  \n",
    "- Classification report\n",
    "\n",
    "Then we interpret the Random Forest using:\n",
    "- Feature importances\n",
    "- Time-based robustness checks\n",
    "- Partial Dependence Plots (PDPs) for:\n",
    "  - Time features (hour, weekday)\n",
    "  - Agency dummies (e.g., DEP vs NYPD)\n",
    "  - Borough dummies (e.g., Manhattan vs Bronx)\n",
    "\n",
    "These results deepen understanding of governance mechanisms and support *RQ2 & RQ3*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8abe70-1389-4538-a409-37b49e7ea3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Block 3 – Predictive Modeling (24h closure prediction)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23aad23-d340-4c10-9ccf-756cdc1b89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make sure is_weekend is 0/1\n",
    "model_df[\"is_weekend\"] = model_df[\"is_weekend\"].astype(int)\n",
    "\n",
    "# 2. Define feature columns and target column.\n",
    "numeric_features = [\"hour\", \"dayofweek\", \"month\", \"is_weekend\"]\n",
    "categorical_features = [\"Borough\", \"Complaint Type\", \"Descriptor\", \"Location Type\", \"Agency\"]\n",
    "target_col = \"closed_24h\"\n",
    "\n",
    "# Convert numerical features to float to avoid PDP's FutureWarning.\n",
    "num_cols_to_float = [\"hour\", \"dayofweek\", \"month\", \"is_weekend\"]\n",
    "model_df[num_cols_to_float] = model_df[num_cols_to_float].astype(float)\n",
    "\n",
    "X = model_df[numeric_features + categorical_features]\n",
    "y = model_df[target_col]\n",
    "\n",
    "# 3. Randomly split into training/test sets (for main evaluation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test), y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5df8bc-267d-45d8-89b5-8bbc57671d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Preprocessing: Numerical features pass through directly, categorical features are One-Hot encoded.\n",
    "numeric_transformer = \"passthrough\"\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. General evaluation function: calculates ROC-AUC, PR-AUC, and classification report\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    pr = average_precision_score(y_test, y_proba)\n",
    "    \n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"ROC-AUC:\", round(roc, 4))\n",
    "    print(\"PR-AUC :\", round(pr, 4))\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"roc_auc\": roc,\n",
    "        \"pr_auc\": pr\n",
    "    }\n",
    "print(\"preprocess and evaluate_model are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1497247-ff4f-4562-a6b5-32ee048690f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Baseline Model: Logistic Regression\n",
    "log_reg = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 7. Main model: Random Forest\n",
    "rf_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 8. Evaluate the two models on a random train/test split.\n",
    "results = []\n",
    "results.append(evaluate_model(\"Logistic Regression\", log_reg, X_train, y_train, X_test, y_test))\n",
    "results.append(evaluate_model(\"Random Forest\", rf_clf, X_train, y_train, X_test, y_test))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2db37-8706-45e5-bf23-ca820d9ddb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Refit the Random Forest model on a random train/test split's training set for explanation (feature importance & PDP).\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# 10. Obtained the internal RF model and OneHotEncoder.\n",
    "rf_inner = rf_clf.named_steps[\"clf\"]\n",
    "ohe = rf_clf.named_steps[\"preprocess\"].named_transformers_[\"cat\"]\n",
    "\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "all_feature_names = numeric_features + list(ohe_feature_names)\n",
    "\n",
    "# 11. Calculate feature_importances_ and take the top 20.\n",
    "importances = rf_inner.feature_importances_\n",
    "idx = np.argsort(importances)[::-1][:20]\n",
    "\n",
    "top_features = [(all_feature_names[i], importances[i]) for i in idx]\n",
    "top_features_df = pd.DataFrame(top_features, columns=[\"feature\", \"importance\"])\n",
    "top_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160bf73b-0cb8-4868-aa8c-d7d39a20a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Time split based on Created Date: the first half for training, the second half for testing\n",
    "min_date = model_df[\"Created Date\"].min()\n",
    "max_date = model_df[\"Created Date\"].max()\n",
    "print(\"Min date:\", min_date)\n",
    "print(\"Max date:\", max_date)\n",
    "\n",
    "mid_date = min_date + (max_date - min_date) / 2\n",
    "mid_date\n",
    "\n",
    "train_mask = model_df[\"Created Date\"] < mid_date\n",
    "test_mask  = model_df[\"Created Date\"] >= mid_date\n",
    "\n",
    "X_time_train = model_df.loc[train_mask, numeric_features + categorical_features]\n",
    "y_time_train = model_df.loc[train_mask, target_col]\n",
    "\n",
    "X_time_test  = model_df.loc[test_mask, numeric_features + categorical_features]\n",
    "y_time_test  = model_df.loc[test_mask, target_col]\n",
    "\n",
    "len(X_time_train), len(X_time_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b739b9c-0ace-4929-a50a-041cdf9ba7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-evaluate Logistic & RF on time slicing.\n",
    "results_time = []\n",
    "results_time.append(evaluate_model(\"Logistic (time-split)\", log_reg, X_time_train, y_time_train, X_time_test, y_time_test))\n",
    "results_time.append(evaluate_model(\"RandomForest (time-split)\", rf_clf, X_time_train, y_time_train, X_time_test, y_time_test))\n",
    "\n",
    "results_time_df = pd.DataFrame(results_time)\n",
    "results_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7952f-d081-4f17-837f-6b2e67fac6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Plot PDP (Partial Dependence Plot) for continuous time features (hour, dayofweek)\n",
    "features_to_plot = [\"hour\", \"dayofweek\"]\n",
    "feature_indices = [all_feature_names.index(f) for f in features_to_plot]\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    rf_clf,\n",
    "    X_train,\n",
    "    features=feature_indices,\n",
    "    feature_names=all_feature_names,\n",
    "    kind=\"average\",\n",
    "    grid_resolution=20\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5773d15-89e8-4248-b97a-9becbe050d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Before categorical PDPs: get inner RF + transformed X (dense) ===\n",
    "\n",
    "rf_inner = rf_clf.named_steps[\"clf\"]\n",
    "preprocess = rf_clf.named_steps[\"preprocess\"]\n",
    "\n",
    "X_train_trans = preprocess.transform(X_train)\n",
    "\n",
    "# If it's a sparse matrix, convert it to a dense ndarray to avoid the csr_matrix error reported by PDP + matplotlib.\n",
    "from scipy.sparse import issparse\n",
    "if issparse(X_train_trans):\n",
    "    X_train_trans = X_train_trans.toarray()\n",
    "\n",
    "X_train_trans.shape, len(all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc3068-1a04-4201-a094-a169663e753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. PDP for Agency dummies: focus on NYPD and DEP\n",
    "\n",
    "# First, confirm which Agency dummy entries are in all_feature_names.\n",
    "agency_dummy_names = [name for name in all_feature_names if name.startswith(\"Agency_\")]\n",
    "agency_dummy_names\n",
    "\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "#  DEP & NYPD\n",
    "target_agencies = [\"Agency_DEP\", \"Agency_NYPD\"]\n",
    "target_indices = [\n",
    "    all_feature_names.index(name)\n",
    "    for name in target_agencies\n",
    "    if name in all_feature_names\n",
    "]\n",
    "\n",
    "for idx in target_indices:\n",
    "    fname = all_feature_names[idx]\n",
    "    disp = PartialDependenceDisplay.from_estimator(\n",
    "        rf_inner,\n",
    "        X_train_trans,\n",
    "        features=[idx],              \n",
    "        feature_names=all_feature_names,\n",
    "        kind=\"average\",\n",
    "        grid_resolution=2            \n",
    "    )\n",
    "    plt.title(f\"PDP for {fname}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4172db-3511-442f-a15b-cd3679bb2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. PDP for Borough dummies\n",
    "\n",
    "#“Conditional on complaint type and time of day, the predicted probability of closing a complaint within 24 hours is higher in Manhattan than in Bronx, suggesting spatial disparities in service delivery.”\n",
    "\n",
    "target_boroughs = [\"Borough_MANHATTAN\", \"Borough_BRONX\"]\n",
    "target_indices = [\n",
    "    all_feature_names.index(name)\n",
    "    for name in target_boroughs\n",
    "    if name in all_feature_names\n",
    "]\n",
    "\n",
    "for idx in target_indices:\n",
    "    fname = all_feature_names[idx]\n",
    "    disp = PartialDependenceDisplay.from_estimator(\n",
    "        rf_inner,\n",
    "        X_train_trans,\n",
    "        features=[idx],\n",
    "        feature_names=all_feature_names,\n",
    "        kind=\"average\",\n",
    "        grid_resolution=2,\n",
    "        categorical_features=[idx],\n",
    "    )\n",
    "    plt.title(f\"PDP for {fname}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd77af-e558-4025-8620-737eceafa904",
   "metadata": {},
   "source": [
    "# **Block 4 — Equity & Bias Analysis**\n",
    "This section investigates spatial, institutional, and data-driven disparities in noise complaint responses.  \n",
    "We examine:\n",
    "- Borough-level closure rate disparities  \n",
    "- Complaint Type disparities  \n",
    "- Borough × Complaint Type intersections  \n",
    "- Agency × Borough interactions  \n",
    "- Missing Location Type and its relationship to slower response  \n",
    "\n",
    "These analyses address *RQ3: Are there inequities or systemic biases in NYC’s noise complaint response system?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf40ab0-638b-49f0-9d64-df0f31c27f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Borough disparities\n",
    "\n",
    "borough_stats = (\n",
    "    model_df\n",
    "    .groupby(\"Borough\")\n",
    "    .agg(\n",
    "        n_cases=(\"closed_24h\", \"size\"),\n",
    "        closed_24h_rate=(\"closed_24h\", \"mean\"),\n",
    "        median_response_hours=(\"response_hours\", \"median\")\n",
    "    )\n",
    "    .sort_values(\"closed_24h_rate\")\n",
    ")\n",
    "\n",
    "borough_stats.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ccc1ca-edfe-46da-9058-f4f970c23d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "borough_stats[\"closed_24h_rate\"].plot(kind=\"barh\", color=\"steelblue\")\n",
    "plt.title(\"24h Closure Rate by Borough\")\n",
    "plt.xlabel(\"Proportion closed within 24h\")\n",
    "plt.ylabel(\"Borough\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35cf1a0-58a8-4c70-91b0-1709e582b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the top 10 most frequent noise categories are analyzed.\n",
    "top10_types = noise_df[\"Complaint Type\"].value_counts().head(10).index\n",
    "\n",
    "type_stats = (\n",
    "    model_df[model_df[\"Complaint Type\"].isin(top10_types)]\n",
    "    .groupby(\"Complaint Type\")[\"closed_24h\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "type_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d41453-a450-4bf6-bfa3-a49db3259870",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "type_stats.plot(kind=\"barh\")\n",
    "plt.title(\"24h Closure Rate by Complaint Type (Top 10)\")\n",
    "plt.xlabel(\"Proportion closed within 24h\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cc22b-59e5-4eb7-8c7e-d5df5e94491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borough × Complaint Type × 24h closure\n",
    "intersection_bt = (\n",
    "    model_df\n",
    "    .groupby([\"Borough\", \"Complaint Type\"])[\"closed_24h\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "intersection_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20882e-4c24-4633-8f3f-4daa05951417",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_type = \"Noise - Residential\"\n",
    "plt.figure(figsize=(8,5))\n",
    "intersection_bt[target_type].sort_values().plot(kind=\"barh\")\n",
    "plt.title(f\"24h Closure Rate by Borough for {target_type}\")\n",
    "plt.xlabel(\"Proportion closed within 24h\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c4b8a-5d32-49ff-a6b6-9351a86e7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_boro = (\n",
    "    model_df\n",
    "    .groupby([\"Agency\", \"Borough\"])[\"closed_24h\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "agency_boro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a862c-d679-4e03-92d0-f8603448dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_boro.T.plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"24h Closure Rate by Agency × Borough\")\n",
    "plt.ylabel(\"Proportion closed within 24h\")\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Agency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5702f-58e5-4a29-a888-ff0baee7953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"loc_missing\"] = model_df[\"Location Type\"].isna().astype(int)\n",
    "\n",
    "missing_stats = (\n",
    "    model_df\n",
    "    .groupby(\"loc_missing\")[\"closed_24h\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "missing_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a69f020-ea5a-4880-bdcf-5ab3a4df315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "missing_stats.plot(kind=\"bar\", color=[\"gray\", \"red\"])\n",
    "plt.title(\"24h Closure Rate: Missing vs Non-missing Location Type\")\n",
    "plt.xticks([0,1], [\"Non-missing\", \"Missing\"], rotation=0)\n",
    "plt.ylabel(\"Proportion closed within 24h\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a01d68-f55a-42e4-91aa-43f337a3853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_by_borough = (\n",
    "    model_df\n",
    "    .groupby(\"Borough\")[\"loc_missing\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "missing_by_borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c22e4-ea4f-4bcc-a5d5-4c2bd025487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "missing_by_borough.plot(kind=\"barh\")\n",
    "plt.title(\"Missing Location Type Rate by Borough\")\n",
    "plt.xlabel(\"Missing Rate\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93e6fe-b3d6-496c-8b12-f9383e997473",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script nyc_noise_analysis_full.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051e49c-d260-4d4c-8b14-e57c3bc1d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"closed_24h\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ab077-6451-4671-a462-99195fc67e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"response_hours\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ff3e6-0298-4857-a5b8-14831795b3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
